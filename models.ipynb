{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZmHGDuwLSpS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6408ed6b-b09d-4952-90bd-5ca2a6577478"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import load_model\n",
        "from keras import regularizers\n",
        "from keras.layers.core import Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "from keras.metrics import Precision\n",
        "from keras.metrics import Recall\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D22QsR1mLcB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "def DataExpansion(a):\n",
        "    with open(a, 'rb') as f:\n",
        "      l = pickle.load(f, encoding='bytes')\n",
        "      f.close()\n",
        "      \n",
        "    \n",
        "    training_data = np.array(l[0][0])\n",
        "    training_data_out = np.array(l[0][1])\n",
        "    test_data = np.array(l[1][0])\n",
        "    test_data_out = np.array(l[1][1])\n",
        "    \n",
        "    training_data = training_data.reshape(training_data.shape[0],224,224,1)\n",
        "    test_data = test_data.reshape(test_data.shape[0],224,224,1)\n",
        "#    training_data = training_data.astype('float32')\n",
        "#    test_data = test_data.astype('float32')\n",
        "    number_of_classes = 2\n",
        "    from keras.utils import np_utils\n",
        "    training_data_out = np_utils.to_categorical(training_data_out, number_of_classes)\n",
        "    test_data_out = np_utils.to_categorical(test_data_out, number_of_classes)\n",
        "    training_data_out = training_data_out[:,0]\n",
        "    test_data_out = test_data_out[:,0]\n",
        "    \n",
        "    return training_data,training_data_out,test_data,test_data_out\n",
        "          \n",
        "def data():\n",
        "  X_train = pd.read_csv('/content/drive/My Drive/X_train1.csv')\n",
        "  y_train = pd.read_csv('/content/drive/My Drive/Y_train1.csv')\n",
        "  X_test = pd.read_csv('/content/drive/My Drive/X_test_all.csv')\n",
        "  y_test = pd.read_csv('/content/drive/My Drive/Y_test_all.csv')\n",
        "  X_train = X_train.iloc[:,1:].values\n",
        "  X_test = X_test.iloc[:,1:].values\n",
        "  y_train = y_train.iloc[:,1:].values\n",
        "  y_test = y_test.iloc[:,1:].values\n",
        "  X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.2, random_state=12345)\n",
        "  X_train = X_train.astype('float32')\n",
        "  X_test = X_test.astype('float32')\n",
        "  X_val = X_val.astype('float32')\n",
        "  nb_classes = 12\n",
        "  y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "  y_val = np_utils.to_categorical(y_val, nb_classes)\n",
        "  y_test= np_utils.to_categorical(y_test, nb_classes)\n",
        "  y_train = y_train[:,0:11]\n",
        "  y_test = y_test[:,0:11]\n",
        "  y_val = y_val[:,0:11]\n",
        "  X_train = X_train.reshape(X_train.shape[0],224,224,1)\n",
        "  X_test = X_test.reshape(X_test.shape[0],224,224,1)\n",
        "  X_val = X_val.reshape(X_val.shape[0],224,224,1)\n",
        "  return X_train, y_train, X_val, y_val\n",
        "\n",
        "def model():\n",
        "    classifier = Sequential()\n",
        "    #convolution layer with rectifier function\n",
        "    # input_shape = (64,64,1) for 'tensorflow backend' and (1,64,64) for 'theano backend'\n",
        "    classifier.add(Conv2D(32,(3,3),input_shape = (224,224,1),activation = 'relu'))\n",
        "    #classifier.add(BatchNormalization())\n",
        "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "    classifier.add(Conv2D(64,(3,3),activation = 'relu'))\n",
        "    #classifier.add(BatchNormalization())\n",
        "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "    classifier.add(Conv2D(128,(3,3),activation = 'relu'))\n",
        "    #classifier.add(BatchNormalization())\n",
        "    #classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "    classifier.add(Conv2D(128,(3,3),activation = 'relu'))\n",
        "    #classifier.add(BatchNormalization())\n",
        "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "    classifier.add(Conv2D(256,(3,3),activation = 'relu'))\n",
        "    #classifier.add(BatchNormalization())\n",
        "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "    classifier.add(Flatten())\n",
        "    classifier.add(Dense(units =512,activation = 'relu')\n",
        "    classifier.add(Dense(units = 1,activation = 'sigmoid'))\n",
        "    classifier.summary()\n",
        "    classifier.compile(optimizer = 'adam',loss = 'binary_crossentropy', metrics = ['accuracy','Precision','Recall'])  \n",
        "    \n",
        "    return classifier\n",
        "\n",
        "def model_2():\n",
        "  classifier = Sequential()\n",
        "  classifier.add(Conv2D(32,3,3,input_shape = (224,224,1),activation = 'relu'))\n",
        "  #classifier.add(BatchNormalization())\n",
        "  classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "  classifier.add(Conv2D(64,3,3,activation = 'relu'))\n",
        "  #classifier.add(BatchNormalization())\n",
        "  classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "  classifier.add(Conv2D(128,3,3,activation = 'relu'))\n",
        "  #classifier.add(BatchNormalization())\n",
        "  classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "  classifier.add(Conv2D(128,3,3,activation = 'relu'))\n",
        "  #classifier.add(BatchNormalization())\n",
        "  classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "  classifier.add(Conv2D(256,3,3,activation = 'relu'))\n",
        "  # classifier.add(BatchNormalization())\n",
        "  #classifier.add(Conv2D(32,3,3,activation = 'relu'))\n",
        "  # classifier.add(BatchNormalization())\n",
        "  classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "  classifier.add(Flatten())\n",
        "  classifier.add(Dense(units =512,activation = 'relu'))\n",
        "  classifier.add(Dense(units = 1,activation = 'sigmoid'))\n",
        "  classifier.summary()\n",
        "  classifier.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['categorical_accuracy','Precision','Recall'])\n",
        "\n",
        "  return classifier\n",
        "\n",
        "   \n",
        "def run_model(model,trd,trdo,tsd,tsdo,n_ep):\n",
        "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                       shear_range=0.2,\n",
        "                                       zoom_range=0.2,\n",
        "                                       horizontal_flip=True)\n",
        "    \n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    \n",
        "    training_set = train_datagen.flow(trd,trdo,batch_size=32)\n",
        "                                                     \n",
        "    test_set = test_datagen.flow(tsd,tsdo,batch_size=32)\n",
        "                                                \n",
        "    model.fit_generator(training_set,\n",
        "                        steps_per_epoch=trdo.shape[0],\n",
        "                        epochs=n_ep,\n",
        "                        validation_data=test_set,\n",
        "                        validation_steps=tsdo.shape[0],\n",
        "                        callbacks = [EarlyStopping(monitor='val_acc', patience=3)])\n",
        "    return model\n",
        "    \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOtBCoEUHKSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a,b,c,d = DataExpansion('/content/drive/My Drive/MODS_all_data_bw_224_224_0.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZvHf0lIGVdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1,5):\n",
        "    if i == 1:\n",
        "        run_model(model_2(),a,b,c,d,15).save('binary_class_'+str(i)+'.h5')\n",
        "    else:\n",
        "        mod = load_model('/content/binary_class_'+str(i-1)+'.h5')\n",
        "        run_model(mod,a,b,c,d,15).save('/content/binary_class_'+str(i)+'.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOYa4msNGJVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a,b,c,d = data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zinUvpq6ESpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(1,5):\n",
        "    if i == 1:\n",
        "        run_model(model_2(),a,b,c,d,15).save('multi_class_'+str(i)+'.h5')\n",
        "    else:\n",
        "        mod = load_model('/content/multi_class_'+str(i-1)+'.h5')\n",
        "        run_model(mod,a,b,c,d,15).save('/content/multi_class_'+str(i)+'.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUWSjTqaH1SD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}